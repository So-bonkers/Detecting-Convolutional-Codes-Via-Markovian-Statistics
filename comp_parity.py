#!/usr/bin/env python3
"""
comp_parity.py

Implementation of the **parity-template detector**
used as a *baseline* in **Section IV** of the WCNC-2026 paper:

    "Detecting Convolutional Codes via a Markovian Statistic"

This script implements hypothesis testing based on *parity-template satisfaction*
counts derived from exact parity-check equations. The method follows the
syndrome/parity-template philosophy used in the literature (e.g., Moosavi &
Larsson, GLOBECOM 2011) and is included **only for comparison** with the proposed
Markov-chain-based detector.

──────────────────────────────────────────────────────────────────────────────
MATHEMATICAL CONTEXT (baseline detector)
──────────────────────────────────────────────────────────────────────────────

Let a parity template be a time-domain equation of the form

    ⊕_{(j,s)∈S} v_j[t−s] = 0,                                      (P-Eq)

which holds deterministically for all noiseless codewords generated by a given
convolutional code.

Given a noisy received sequence y_j[t] over a BSC(p), define the empirical
satisfaction fraction

    \hat{P}(N) = (1/M) ∑_{t∈A} 1{ ⊕_{(j,s)∈S} y_j[t−s] = 0 },

where A is the set of valid anchor positions and M = |A|.

The baseline hypothesis test is then

    \hat{P}(N) ≷_H1^H2 γ,

where γ is a manually tuned threshold (see Fig. 4 in the paper). Unlike the
proposed likelihood-ratio test, γ has **no analytical optimum** and must be
selected empirically.

This file:
  • Applies parity templates to noisy data
  • Computes \hat{P}(N) under two hypotheses
  • Performs threshold-based detection

"""

import random
import math
from typing import List, Tuple
import numpy as np

from parity_eqn_check import (
    parse_poly_token,
    build_parity_system,
    nullspace_mod2,
    parity_vector_to_equation,
)

# ──────────────────────────────────────────────────────────────────────────────
# Convolutional encoder (time-domain)
# ──────────────────────────────────────────────────────────────────────────────

def encode_convolutional(u_bits: List[int], generators: List[List[List[int]]], m: int):
    """
    Encode a binary input sequence using a feed-forward convolutional encoder.

    This is used to generate noiseless reference codewords for parity testing.
    """
    n = len(generators)
    T = len(u_bits) + m
    outputs = [[0] * T for _ in range(n)]

    for t in range(T):
        for j in range(n):
            acc = 0
            for shift, bit in enumerate(generators[j][0]):
                if bit and t - shift >= 0 and t - shift < len(u_bits):
                    acc ^= u_bits[t - shift]
            outputs[j][t] = acc

    return outputs


# ──────────────────────────────────────────────────────────────────────────────
# Parity-template evaluation
# ──────────────────────────────────────────────────────────────────────────────

def parity_satisfaction_fraction(y: List[List[int]], template: List[Tuple[int, int]]):
    """
    Compute the empirical parity satisfaction fraction \hat{P}(N).

    Parameters:
      y[j][t]   : received noisy sequence
      template  : list of (output_index j, delay s)
    """
    n = len(y)
    T = len(y[0])
    max_delay = max(s for (_, s) in template)

    satisfied = 0
    total = 0

    for t in range(max_delay, T):
        xor_sum = 0
        for (j, s) in template:
            xor_sum ^= y[j][t - s]
        total += 1
        if xor_sum == 0:
            satisfied += 1

    return satisfied / total if total > 0 else 0.0


# ──────────────────────────────────────────────────────────────────────────────
# Hypothesis testing using parity templates
# ──────────────────────────────────────────────────────────────────────────────

def parity_detector(y: List[List[int]], template: List[Tuple[int, int]], gamma: float):
    """
    Perform parity-template hypothesis testing:

        decide H1 if \hat{P}(N) ≥ γ,
        decide H2 otherwise.
    """
    P_hat = parity_satisfaction_fraction(y, template)
    return P_hat >= gamma, P_hat


# ──────────────────────────────────────────────────────────────────────────────
# Example Monte-Carlo experiment (baseline)
# ──────────────────────────────────────────────────────────────────────────────

if __name__ == "__main__":
    # Example: rate-1/2 convolutional codes
    g1 = [parse_poly_token("7")]
    g2 = [parse_poly_token("5")]
    generators = [g1, g2]

    m = 2
    deg_h = m + 3

    # Build parity templates
    A = build_parity_system(generators, deg_h)
    basis = nullspace_mod2(A)

    # Choose first parity template
    h_vec = []
    for j in range(len(generators)):
        h_vec.append(basis[0][j*(deg_h+1):(j+1)*(deg_h+1)].tolist())

    print("Using parity equation:")
    print(parity_vector_to_equation(h_vec))

    # Convert to template (j, s)
    template = []
    for j, poly in enumerate(h_vec):
        for s, bit in enumerate(poly):
            if bit:
                template.append((j, s))

    # Simulation parameters
    N = 200
    p = 0.1
    gamma = 0.6
    trials = 1000

    correct = 0

    for _ in range(trials):
        u = [random.randint(0, 1) for _ in range(N)]
        v = encode_convolutional(u, generators, m)

        # Apply BSC(p)
        y = [[bit ^ (random.random() < p) for bit in stream] for stream in v]

        decision, P_hat = parity_detector(y, template, gamma)
        correct += int(decision)

    print(f"Baseline parity detector accuracy: {correct/trials:.3f}")
